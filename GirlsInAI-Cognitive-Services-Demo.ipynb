{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "## Analyse an image (Computer Vision API)\n\nWe will use Microsoft Computer Vision API to analyse the image below. We will initially pull out all the information provided by the API endpoint, and later narrow it down to colours availabl on the image, as well as pull out a caption, generated by the service for this image. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![alt text](https://d3e1m60ptf1oym.cloudfront.net/833a3a4b-f635-42d6-86a2-d63c08145513/L23025-FR-01_uxga.jpg)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To be able to use this service you need to have access to [Azure Portal](http://portal.azure.com) and create an instance of the Vision API Cognitive Service."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "First, let's try calling the service to analyse the given image and return all available feautures, as decribed in the [API Reference](https://westus.dev.cognitive.microsoft.com/docs/services/56f91f2d778daf23d8ec6739/operations/56f91f2e778daf14a499e1fa)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import httplib, urllib, base64, json\n\n# Replace the subscription_key string value with your valid subscription key.\nvisionapi_key = \"<ADD-YOUR-AZURE-COGNITIVE-SERVICES-KEY>\"\nsubscription_key = visionapi_key\n\n# Replace to match your region.\n\nuri_base = 'westus.api.cognitive.microsoft.com'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Ocp-Apim-Subscription-Key': subscription_key,\n}\n\nparams = urllib.urlencode({\n    'language': 'en',\n    'visualFeatures': 'Categories, Description, Tags, Faces, ImageType, Color'\n    #'visualFeatures': 'Description' #Demo 2\n    \n})\n\nbody = \"{'url':'https://d3e1m60ptf1oym.cloudfront.net/833a3a4b-f635-42d6-86a2-d63c08145513/L23025-FR-01_uxga.jpg'}\"\n\ntry:\n    # Execute the REST API call and get the response.\n    conn = httplib.HTTPSConnection(uri_base)\n    conn.request(\"POST\", \"/vision/v1.0/analyze?%s\" % params, body, headers)\n    response = conn.getresponse()\n    data = response.read()\n\n    # 'data' contains the JSON data. The following formats the JSON data for display.\n    parsed = json.loads(data.decode())\n    print (\"Response:\")\n    print (json.dumps(parsed, sort_keys=True, indent=2))\n    conn.close()\n\nexcept Exception as e:\n    print('Error:')\n    print(e)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Response:\n{\n  \"categories\": [\n    {\n      \"detail\": {\n        \"landmarks\": []\n      }, \n      \"name\": \"building_\", \n      \"score\": 0.18359375\n    }, \n    {\n      \"detail\": {\n        \"landmarks\": []\n      }, \n      \"name\": \"outdoor_\", \n      \"score\": 0.03125\n    }\n  ], \n  \"color\": {\n    \"accentColor\": \"3A6586\", \n    \"dominantColorBackground\": \"White\", \n    \"dominantColorForeground\": \"White\", \n    \"dominantColors\": [\n      \"White\", \n      \"Grey\"\n    ], \n    \"isBWImg\": false, \n    \"isBwImg\": false\n  }, \n  \"description\": {\n    \"captions\": [\n      {\n        \"confidence\": 0.9439551981908587, \n        \"text\": \"a body of water with a city in the background\"\n      }\n    ], \n    \"tags\": [\n      \"outdoor\", \n      \"water\", \n      \"boat\", \n      \"harbor\", \n      \"building\", \n      \"parked\", \n      \"sitting\", \n      \"group\", \n      \"ocean\", \n      \"city\", \n      \"small\", \n      \"people\", \n      \"many\", \n      \"dock\", \n      \"bunch\", \n      \"overlooking\", \n      \"large\", \n      \"body\", \n      \"covered\", \n      \"old\", \n      \"standing\", \n      \"docked\", \n      \"beach\", \n      \"man\", \n      \"snow\", \n      \"riding\", \n      \"umbrella\", \n      \"skiing\"\n    ]\n  }, \n  \"faces\": [], \n  \"imageType\": {\n    \"clipArtType\": 0, \n    \"lineDrawingType\": 0\n  }, \n  \"metadata\": {\n    \"format\": \"Jpeg\", \n    \"height\": 1067, \n    \"width\": 1600\n  }, \n  \"requestId\": \"b51ea014-45cf-4e87-aecb-b7732bb810c5\", \n  \"tags\": [\n    {\n      \"confidence\": 0.9984024167060852, \n      \"name\": \"sky\"\n    }, \n    {\n      \"confidence\": 0.9884501099586487, \n      \"name\": \"skyscraper\"\n    }, \n    {\n      \"confidence\": 0.9809728860855103, \n      \"name\": \"outdoor\"\n    }, \n    {\n      \"confidence\": 0.9632894992828369, \n      \"name\": \"city\"\n    }, \n    {\n      \"confidence\": 0.9587729573249817, \n      \"name\": \"building\"\n    }, \n    {\n      \"confidence\": 0.9214897155761719, \n      \"name\": \"tower\"\n    }, \n    {\n      \"confidence\": 0.8651860952377319, \n      \"name\": \"cityscape\"\n    }, \n    {\n      \"confidence\": 0.8600019812583923, \n      \"name\": \"skyline\"\n    }, \n    {\n      \"confidence\": 0.7252653241157532, \n      \"name\": \"cloud\"\n    }, \n    {\n      \"confidence\": 0.7075778245925903, \n      \"name\": \"downtown\"\n    }, \n    {\n      \"confidence\": 0.4943923354148865, \n      \"name\": \"harbor\"\n    }, \n    {\n      \"confidence\": 0.10571517050266266, \n      \"name\": \"several\"\n    }\n  ]\n}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can also choose to only pick up the caption from the response and process it as required (show it below, in our case)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import httplib, urllib, base64, json\n\n# Replace the subscription_key string value with your valid subscription key.\nsubscription_key = visionapi_key\n\n# Replace to match your region.\n\nuri_base = 'westus.api.cognitive.microsoft.com'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Ocp-Apim-Subscription-Key': subscription_key,\n}\n\nparams = urllib.urlencode({\n    'language': 'en',\n    'visualFeatures': 'Description'\n    #'visualFeatures': 'Description' #Demo 2\n    \n})\n\nbody = \"{'url':'https://d3e1m60ptf1oym.cloudfront.net/833a3a4b-f635-42d6-86a2-d63c08145513/L23025-FR-01_uxga.jpg'}\"\n\ntry:\n    # Execute the REST API call and get the response.\n    conn = httplib.HTTPSConnection(uri_base)\n    conn.request(\"POST\", \"/vision/v1.0/analyze?%s\" % params, body, headers)\n    response = conn.getresponse()\n    data = response.read()\n\n    parsed = json.loads(data.decode())\n    caption = json.dumps(parsed['description']['captions'][0], sort_keys=True, indent=2)\n    print (\"Response:\")\n    print (caption)\n    conn.close()\n\nexcept Exception as e:\n    print('Error:')\n    print(e)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Response:\n{\n  \"confidence\": 0.9439551981908587, \n  \"text\": \"a body of water with a city in the background\"\n}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "====\n\nThere is also a separate API call that can be used to generate various descriptions for a given image: [Describe Image](https://westus.dev.cognitive.microsoft.com/docs/services/56f91f2d778daf23d8ec6739/operations/56f91f2e778daf14a499e1fe) API endpoint. We will generate 5 different caption for the picture above."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import httplib, urllib, base64, json\n\n# Replace the subscription_key string value with your valid subscription key.\nsubscription_key = visionapi_key\n\n# Replace to match your region.\n\nuri_base = 'westus.api.cognitive.microsoft.com'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Ocp-Apim-Subscription-Key': subscription_key,\n}\n\nparams = urllib.urlencode({\n    'maxCandidates': 5    #Maximum number of candidate descriptions to be returned. The default is 1.\n})\n\nbody = \"{'url': 'https://d3e1m60ptf1oym.cloudfront.net/833a3a4b-f635-42d6-86a2-d63c08145513/L23025-FR-01_uxga.jpg'}\"\n\ntry:\n    # Execute the REST API call and get the response.\n    conn = httplib.HTTPSConnection(uri_base)\n    conn.request(\"POST\", \"/vision/v1.0/describe?%s\" % params, body, headers) # \"describe\" method\n    response = conn.getresponse()\n    data = response.read()\n\n    parsed = json.loads(data.decode())\n    caption = json.dumps(parsed[\"description\"][\"captions\"], sort_keys=True, indent=2)\n    print (\"Response:\")\n    print (caption)\n    conn.close()\n\nexcept Exception as e:\n    print('Error:')\n    print(e)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Response:\n[\n  {\n    \"confidence\": 0.9439551981908587, \n    \"text\": \"a body of water with a city in the background\"\n  }, \n  {\n    \"confidence\": 0.9429551981908587, \n    \"text\": \"a large body of water with a city in the background\"\n  }, \n  {\n    \"confidence\": 0.940710705601899, \n    \"text\": \"a body of water with a city in the distance\"\n  }, \n  {\n    \"confidence\": 0.7589772805640238, \n    \"text\": \"a small boat in a body of water with a city in the background\"\n  }, \n  {\n    \"confidence\": 0.7579772805640238, \n    \"text\": \"a boat on a body of water with a city in the background\"\n  }\n]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "\nI hope you can see how easy it is to integrate these APIs into your code. \n\nDon't forget all you need to do is\n* Use Azure Pass to create your Azure subscription (one per table)\n* Create a new Cognitive Service on Azure portal\n* Take a note of endpoint URL and KEY 1 from \"Keys\" menu\n* Make a REST API call using those two pieces in the code written in your preferred language\n\n\n===\n\nThe End!"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}