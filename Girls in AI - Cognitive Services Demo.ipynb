{
  "cells": [
    {
      "metadata": {
        "collapsed": true
      },
      "cell_type": "markdown",
      "source": "## Analyse an image (Computer Vision API)\n\nWe will use Microsoft Computer Vision API to analyse the image below. We will initially pull out all the information provided by the API endpoint, and later narrow it down to colours availabl on the image, as well as pull out a caption, generated by the service for this image. "
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "![alt text](https://atodmagazine.com/wp-content/uploads/2018/06/SF.jpg)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To be able to use this service you need to have access to [Azure Portal](http://portal.azure.com) and create an instance of the Vision API Cognitive Service."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "First, let's try calling the service to analyse the given image and return all available feautures, as decribed in the [API Reference](https://westus.dev.cognitive.microsoft.com/docs/services/56f91f2d778daf23d8ec6739/operations/56f91f2e778daf14a499e1fa)"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import httplib, urllib, base64, json\n\n# Replace the subscription_key string value with your valid subscription key.\nvisionapi_key = \"<ADD-YOUR-AZURE-COGNITIVE-SERVICES-KEY>\"\nsubscription_key = visionapi_key\n\n# Replace to match your region.\n\nuri_base = 'westus.api.cognitive.microsoft.com'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Ocp-Apim-Subscription-Key': subscription_key,\n}\n\nparams = urllib.urlencode({\n    'language': 'en',\n    'visualFeatures': 'Categories, Description, Tags, Faces, ImageType, Color'\n    #'visualFeatures': 'Description' #Demo 2\n    \n})\n\nbody = \"{'url':'https://atodmagazine.com/wp-content/uploads/2018/06/SF.jpg'}\"\n\ntry:\n    # Execute the REST API call and get the response.\n    conn = httplib.HTTPSConnection(uri_base)\n    conn.request(\"POST\", \"/vision/v1.0/analyze?%s\" % params, body, headers)\n    response = conn.getresponse()\n    data = response.read()\n\n    # 'data' contains the JSON data. The following formats the JSON data for display.\n    parsed = json.loads(data.decode())\n    print (\"Response:\")\n    print (json.dumps(parsed, sort_keys=True, indent=2))\n    conn.close()\n\nexcept Exception as e:\n    print('Error:')\n    print(e)",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Response:\n{\n  \"categories\": [\n    {\n      \"detail\": {\n        \"landmarks\": []\n      }, \n      \"name\": \"outdoor_\", \n      \"score\": 0.08203125\n    }, \n    {\n      \"detail\": {\n        \"landmarks\": []\n      }, \n      \"name\": \"outdoor_oceanbeach\", \n      \"score\": 0.86328125\n    }\n  ], \n  \"color\": {\n    \"accentColor\": \"A67E25\", \n    \"dominantColorBackground\": \"White\", \n    \"dominantColorForeground\": \"White\", \n    \"dominantColors\": [\n      \"White\"\n    ], \n    \"isBWImg\": false, \n    \"isBwImg\": false\n  }, \n  \"description\": {\n    \"captions\": [\n      {\n        \"confidence\": 0.955892494992103, \n        \"text\": \"a group of people on a beach near a bridge\"\n      }\n    ], \n    \"tags\": [\n      \"outdoor\", \n      \"water\", \n      \"people\", \n      \"beach\", \n      \"bridge\", \n      \"building\", \n      \"large\", \n      \"group\", \n      \"flying\", \n      \"river\", \n      \"long\", \n      \"view\", \n      \"mountain\", \n      \"boat\", \n      \"standing\", \n      \"lake\", \n      \"walking\", \n      \"kite\", \n      \"ocean\", \n      \"man\", \n      \"white\", \n      \"surfing\", \n      \"horse\", \n      \"crowd\", \n      \"field\", \n      \"playing\", \n      \"blue\"\n    ]\n  }, \n  \"faces\": [], \n  \"imageType\": {\n    \"clipArtType\": 0, \n    \"lineDrawingType\": 0\n  }, \n  \"metadata\": {\n    \"format\": \"Jpeg\", \n    \"height\": 700, \n    \"width\": 1300\n  }, \n  \"requestId\": \"c7fbc7ec-5d60-4488-9cd7-ae84f464ce95\", \n  \"tags\": [\n    {\n      \"confidence\": 0.9972479939460754, \n      \"name\": \"sky\"\n    }, \n    {\n      \"confidence\": 0.9946098327636719, \n      \"name\": \"outdoor\"\n    }, \n    {\n      \"confidence\": 0.9851192235946655, \n      \"name\": \"beach\"\n    }, \n    {\n      \"confidence\": 0.9702249765396118, \n      \"name\": \"water\"\n    }, \n    {\n      \"confidence\": 0.824460506439209, \n      \"name\": \"people\"\n    }, \n    {\n      \"confidence\": 0.6980574727058411, \n      \"name\": \"bridge\"\n    }, \n    {\n      \"confidence\": 0.173136904835701, \n      \"name\": \"day\"\n    }\n  ]\n}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We can also choose to only pick up the caption from the response and process it as required (show it below, in our case)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import httplib, urllib, base64, json\n\n# Replace the subscription_key string value with your valid subscription key.\nsubscription_key = visionapi_key\n\n# Replace to match your region.\n\nuri_base = 'westus.api.cognitive.microsoft.com'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Ocp-Apim-Subscription-Key': subscription_key,\n}\n\nparams = urllib.urlencode({\n    'language': 'en',\n    'visualFeatures': 'Description'\n    #'visualFeatures': 'Description' #Demo 2\n    \n})\n\nbody = \"{'url':'https://atodmagazine.com/wp-content/uploads/2018/06/SF.jpg'}\"\n\ntry:\n    # Execute the REST API call and get the response.\n    conn = httplib.HTTPSConnection(uri_base)\n    conn.request(\"POST\", \"/vision/v1.0/analyze?%s\" % params, body, headers)\n    response = conn.getresponse()\n    data = response.read()\n\n    parsed = json.loads(data.decode())\n    caption = json.dumps(parsed['description']['captions'][0], sort_keys=True, indent=2)\n    print (\"Response:\")\n    print (caption)\n    conn.close()\n\nexcept Exception as e:\n    print('Error:')\n    print(e)",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Response:\n{\n  \"confidence\": 0.955892494992103, \n  \"text\": \"a group of people on a beach near a bridge\"\n}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "There is also a separate API call that can be used to get various descriptions for a given image: [Describe Image](https://westus.dev.cognitive.microsoft.com/docs/services/56f91f2d778daf23d8ec6739/operations/56f91f2e778daf14a499e1fe) API endpoint. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import httplib, urllib, base64, json\n\n# Replace the subscription_key string value with your valid subscription key.\nsubscription_key = visionapi_key\n\n# Replace to match your region.\n\nuri_base = 'westus.api.cognitive.microsoft.com'\n\nheaders = {\n    'Content-Type': 'application/json',\n    'Ocp-Apim-Subscription-Key': subscription_key,\n}\n\nparams = urllib.urlencode({\n    'maxCandidates': 5    #Maximum number of candidate descriptions to be returned. The default is 1.\n})\n\nbody = \"{'url': 'https://atodmagazine.com/wp-content/uploads/2018/06/SF.jpg'}\"\n\ntry:\n    # Execute the REST API call and get the response.\n    conn = httplib.HTTPSConnection(uri_base)\n    conn.request(\"POST\", \"/vision/v1.0/describe?%s\" % params, body, headers) # \"describe\" method\n    response = conn.getresponse()\n    data = response.read()\n\n    parsed = json.loads(data.decode())\n    caption = json.dumps(parsed[\"description\"][\"captions\"], sort_keys=True, indent=2)\n    print (\"Response:\")\n    print (caption)\n    conn.close()\n\nexcept Exception as e:\n    print('Error:')\n    print(e)",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Response:\n[\n  {\n    \"confidence\": 0.955892494992103, \n    \"text\": \"a group of people on a beach near a bridge\"\n  }, \n  {\n    \"confidence\": 0.954892494992103, \n    \"text\": \"a group of people on a beach\"\n  }, \n  {\n    \"confidence\": 0.9466375273209776, \n    \"text\": \"a group of people on a bridge over a beach\"\n  }, \n  {\n    \"confidence\": 0.9456375273209776, \n    \"text\": \"a group of people on a beach in front of a bridge\"\n  }, \n  {\n    \"confidence\": 0.9446375273209776, \n    \"text\": \"a group of people on a beach with a bridge in the background\"\n  }\n]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The End!"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 2,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}